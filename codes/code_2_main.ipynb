{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy.stats\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas options\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# garbage collection\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FUNCTION 1: ENCODING FACTORS\n",
    "def encode_factors(df, method = \"label\"):\n",
    "    \n",
    "    # label encoding\n",
    "    if method == \"label\":\n",
    "        factors = [f for f in df.columns if df[f].dtype == \"object\"]\n",
    "        for var in factors:\n",
    "            df[var], _ = pd.factorize(df[var])\n",
    "        \n",
    "    # dummy encoding\n",
    "    if method == \"dummy\":\n",
    "        df = pd.get_dummies(df, drop_first = True)\n",
    "    \n",
    "    # dataset\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FUNCTION 2: AGGREGATIONS\n",
    "def aggregate_data(df, group_var, num_stats = ['mean', 'sum'], \n",
    "                   label = None, sd_zeros = False):\n",
    "    \n",
    "    \n",
    "    ### SEPARATE FEATURES\n",
    "  \n",
    "    # display info\n",
    "    print(\"- Preparing the dataset...\")\n",
    "\n",
    "    # find factors\n",
    "    df_factors = [f for f in df.columns if df[f].dtype == \"object\"]\n",
    "    df_factors = ['fullVisitorId', 'device_operatingSystem', 'geoNetwork_country', 'channelGrouping']\n",
    "        \n",
    "    # partition subsets\n",
    "    if type(group_var) == str:\n",
    "        num_df = df[[group_var] + list(set(df.columns) - set(df_factors))]\n",
    "        fac_df = df[df_factors]\n",
    "    else:\n",
    "        num_df = df[group_var + list(set(df.columns) - set(df_factors))]\n",
    "        fac_df = df[df_factors]      \n",
    "    \n",
    "    # display info\n",
    "    num_facs = fac_df.shape[1] - 1\n",
    "    num_nums = num_df.shape[1] - 1\n",
    "    print(\"- Extracted %.0f factors and %.0f numerics...\" % (num_facs, num_nums))\n",
    "\n",
    "\n",
    "    ##### AGGREGATION\n",
    " \n",
    "    # aggregate numerics\n",
    "    if (num_nums > 0):\n",
    "        print(\"- Aggregating numeric features...\")\n",
    "        if type(group_var) == str:\n",
    "            num_df = num_df.groupby([group_var]).agg(num_stats)\n",
    "            num_df.columns = [\"_\".join(col).strip() for col in num_df.columns.values]\n",
    "            num_df = num_df.sort_index()\n",
    "        else:\n",
    "            num_df = num_df.groupby(group_var).agg(num_stats)\n",
    "            num_df.columns = [\"_\".join(col).strip() for col in num_df.columns.values]\n",
    "            num_df = num_df.sort_index()\n",
    "\n",
    "    # aggregate factors\n",
    "    if (num_facs > 0):\n",
    "        print(\"- Aggregating factor features...\")\n",
    "        if type(group_var) == str:\n",
    "            fac_df = fac_df.groupby([group_var]).agg([(\"mode\", lambda x: scipy.stats.mode(x)[0][0])])\n",
    "            fac_df.columns = [\"_\".join(col).strip() for col in fac_df.columns.values]\n",
    "            fac_df = fac_df.sort_index()\n",
    "        else:\n",
    "            fac_df = fac_df.groupby(group_var).agg([(\"mode\", lambda x: scipy.stats.mode(x)[0][0])])\n",
    "            fac_df.columns = [\"_\".join(col).strip() for col in fac_df.columns.values]\n",
    "            fac_df = fac_df.sort_index()\n",
    "\n",
    "\n",
    "    ##### MERGER\n",
    "\n",
    "    # merge numerics and factors\n",
    "    if ((num_facs > 0) & (num_nums > 0)):\n",
    "        agg_df = pd.concat([num_df, fac_df], axis = 1)\n",
    "    \n",
    "    # use factors only\n",
    "    if ((num_facs > 0) & (num_nums == 0)):\n",
    "        agg_df = fac_df\n",
    "        \n",
    "    # use numerics only\n",
    "    if ((num_facs == 0) & (num_nums > 0)):\n",
    "        agg_df = num_df\n",
    "        \n",
    "\n",
    "    ##### LAST STEPS\n",
    "\n",
    "    # update labels\n",
    "    if (label != None):\n",
    "        agg_df.columns = [label + \"_\" + str(col) for col in agg_df.columns]\n",
    "    \n",
    "    # impute zeros for SD\n",
    "    if (sd_zeros == True):\n",
    "        stdevs = agg_df.filter(like = \"_std\").columns\n",
    "        for var in stdevs:\n",
    "            agg_df[var].fillna(0, inplace = True)\n",
    "            \n",
    "    # dataset\n",
    "    agg_df = agg_df.reset_index()\n",
    "    print(\"- Final dimensions:\", agg_df.shape)\n",
    "    return agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FUNCTION 3: ADD MONTH INDICATOR\n",
    "def add_months_to_end(df, months = 12):\n",
    "\n",
    "    df['months_to_end'] = np.nan\n",
    "\n",
    "    for t in range(months):\n",
    "        t_min = df.date.max() - pd.DateOffset(months = (t + 1))\n",
    "        t_max = df.date.max() - pd.DateOffset(months = t)\n",
    "        df.loc[(df.date > t_min) & (df.date <= t_max), 'months_to_end'] = t + 1\n",
    "        \n",
    "    #df['months_to_end'] = df['months_to_end'].astype('object')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FUNCTION 4: DATE FEATURES\n",
    "def encode_date(df):\n",
    "    \n",
    "    attrs = [\n",
    "             #'Year', 'Month', 'Week', 'Day', \n",
    "             'Dayofweek', \n",
    "             #'Dayofyear',\n",
    "             #'Is_month_end', 'Is_month_start', \n",
    "             #'Is_quarter_end', 'Is_quarter_start', \n",
    "             #'Is_year_end', 'Is_year_start'\n",
    "            ]\n",
    "        \n",
    "    for attr in attrs:\n",
    "        df['date_' + attr] = getattr(df['date'].dt, attr.lower())\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. DATA PARTITIONING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2109926, 40)\n"
     ]
    }
   ],
   "source": [
    "# import CSV\n",
    "df = pd.read_csv(\"../data/data_v1.csv.gz\", compression = \"gzip\", dtype = {'fullVisitorId': 'str'})\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channelGrouping</th>\n",
       "      <th>date</th>\n",
       "      <th>device_browser</th>\n",
       "      <th>device_deviceCategory</th>\n",
       "      <th>device_isMobile</th>\n",
       "      <th>device_operatingSystem</th>\n",
       "      <th>fullVisitorId</th>\n",
       "      <th>geoNetwork_city</th>\n",
       "      <th>geoNetwork_continent</th>\n",
       "      <th>geoNetwork_country</th>\n",
       "      <th>geoNetwork_metro</th>\n",
       "      <th>geoNetwork_networkDomain</th>\n",
       "      <th>geoNetwork_region</th>\n",
       "      <th>geoNetwork_subContinent</th>\n",
       "      <th>totals_bounces</th>\n",
       "      <th>totals_hits</th>\n",
       "      <th>totals_newVisits</th>\n",
       "      <th>totals_pageviews</th>\n",
       "      <th>totals_sessionQualityDim</th>\n",
       "      <th>totals_timeOnSite</th>\n",
       "      <th>totals_totalTransactionRevenue</th>\n",
       "      <th>totals_transactionRevenue</th>\n",
       "      <th>totals_transactions</th>\n",
       "      <th>trafficSource_adContent</th>\n",
       "      <th>trafficSource_adwordsClickInfo.adNetworkType</th>\n",
       "      <th>trafficSource_adwordsClickInfo.gclId</th>\n",
       "      <th>trafficSource_adwordsClickInfo.isVideoAd</th>\n",
       "      <th>trafficSource_adwordsClickInfo.page</th>\n",
       "      <th>trafficSource_adwordsClickInfo.slot</th>\n",
       "      <th>trafficSource_campaign</th>\n",
       "      <th>trafficSource_isTrueDirect</th>\n",
       "      <th>trafficSource_keyword</th>\n",
       "      <th>trafficSource_medium</th>\n",
       "      <th>trafficSource_referralPath</th>\n",
       "      <th>trafficSource_source</th>\n",
       "      <th>visitId</th>\n",
       "      <th>visitNumber</th>\n",
       "      <th>visitStartTime</th>\n",
       "      <th>customDimensions_index</th>\n",
       "      <th>customDimensions_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Organic Search</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>desktop</td>\n",
       "      <td>False</td>\n",
       "      <td>Windows</td>\n",
       "      <td>3162355547410993243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Germany</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>water bottle</td>\n",
       "      <td>organic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>google</td>\n",
       "      <td>1508198450</td>\n",
       "      <td>1</td>\n",
       "      <td>1508198450</td>\n",
       "      <td>4</td>\n",
       "      <td>EMEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Organic Search</td>\n",
       "      <td>2018-05-11</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>mobile</td>\n",
       "      <td>True</td>\n",
       "      <td>Android</td>\n",
       "      <td>7460955084541987166</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>973</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>organic</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>google</td>\n",
       "      <td>1526099341</td>\n",
       "      <td>2</td>\n",
       "      <td>1526099341</td>\n",
       "      <td>4</td>\n",
       "      <td>EMEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Referral</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>desktop</td>\n",
       "      <td>False</td>\n",
       "      <td>Chrome OS</td>\n",
       "      <td>8934116514970143966</td>\n",
       "      <td>Cupertino</td>\n",
       "      <td>Americas</td>\n",
       "      <td>United States</td>\n",
       "      <td>San Francisco-Oakland-San Jose CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>California</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>referral</td>\n",
       "      <td>/a/google.com/transportation/mtv-services/bike...</td>\n",
       "      <td>sites.google.com</td>\n",
       "      <td>1508176307</td>\n",
       "      <td>6</td>\n",
       "      <td>1508176307</td>\n",
       "      <td>4</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Direct</td>\n",
       "      <td>2018-05-11</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>desktop</td>\n",
       "      <td>False</td>\n",
       "      <td>Macintosh</td>\n",
       "      <td>460252456180441002</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Americas</td>\n",
       "      <td>United States</td>\n",
       "      <td>San Francisco-Oakland-San Jose CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>California</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(none)</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>(direct)</td>\n",
       "      <td>1526064483</td>\n",
       "      <td>166</td>\n",
       "      <td>1526064483</td>\n",
       "      <td>4</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Direct</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>mobile</td>\n",
       "      <td>True</td>\n",
       "      <td>Android</td>\n",
       "      <td>7992466427990357681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Americas</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>windjammercable.net</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(none)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(direct)</td>\n",
       "      <td>1508201613</td>\n",
       "      <td>1</td>\n",
       "      <td>1508201613</td>\n",
       "      <td>4</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channelGrouping        date device_browser device_deviceCategory  \\\n",
       "0  Organic Search  2017-10-16        Firefox               desktop   \n",
       "1  Organic Search  2018-05-11         Chrome                mobile   \n",
       "2        Referral  2017-10-16         Chrome               desktop   \n",
       "3          Direct  2018-05-11         Chrome               desktop   \n",
       "4          Direct  2017-10-16         Chrome                mobile   \n",
       "\n",
       "   device_isMobile device_operatingSystem        fullVisitorId  \\\n",
       "0            False                Windows  3162355547410993243   \n",
       "1             True                Android  7460955084541987166   \n",
       "2            False              Chrome OS  8934116514970143966   \n",
       "3            False              Macintosh   460252456180441002   \n",
       "4             True                Android  7992466427990357681   \n",
       "\n",
       "  geoNetwork_city geoNetwork_continent geoNetwork_country  \\\n",
       "0             NaN               Europe            Germany   \n",
       "1       (not set)                 Asia              India   \n",
       "2       Cupertino             Americas      United States   \n",
       "3   San Francisco             Americas      United States   \n",
       "4             NaN             Americas      United States   \n",
       "\n",
       "                    geoNetwork_metro geoNetwork_networkDomain  \\\n",
       "0                                NaN                      NaN   \n",
       "1                                NaN                      NaN   \n",
       "2  San Francisco-Oakland-San Jose CA                      NaN   \n",
       "3  San Francisco-Oakland-San Jose CA                      NaN   \n",
       "4                                NaN      windjammercable.net   \n",
       "\n",
       "  geoNetwork_region geoNetwork_subContinent  totals_bounces  totals_hits  \\\n",
       "0               NaN          Western Europe               1            1   \n",
       "1             Delhi           Southern Asia               0            4   \n",
       "2        California        Northern America               0            2   \n",
       "3        California        Northern America               0            4   \n",
       "4               NaN        Northern America               0            2   \n",
       "\n",
       "   totals_newVisits  totals_pageviews  totals_sessionQualityDim  \\\n",
       "0                 1                 1                         1   \n",
       "1                 0                 3                         1   \n",
       "2                 0                 2                         2   \n",
       "3                 0                 3                         1   \n",
       "4                 1                 2                         1   \n",
       "\n",
       "   totals_timeOnSite  totals_totalTransactionRevenue  \\\n",
       "0                  0                               0   \n",
       "1                973                               0   \n",
       "2                 28                               0   \n",
       "3                 49                               0   \n",
       "4                 38                               0   \n",
       "\n",
       "   totals_transactionRevenue  totals_transactions trafficSource_adContent  \\\n",
       "0                          0                    0                     NaN   \n",
       "1                          0                    0               (not set)   \n",
       "2                          0                    0                     NaN   \n",
       "3                          0                    0               (not set)   \n",
       "4                          0                    0                     NaN   \n",
       "\n",
       "  trafficSource_adwordsClickInfo.adNetworkType  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                          NaN   \n",
       "\n",
       "  trafficSource_adwordsClickInfo.gclId  \\\n",
       "0                                  NaN   \n",
       "1                                  NaN   \n",
       "2                                  NaN   \n",
       "3                                  NaN   \n",
       "4                                  NaN   \n",
       "\n",
       "   trafficSource_adwordsClickInfo.isVideoAd  \\\n",
       "0                                      True   \n",
       "1                                      True   \n",
       "2                                      True   \n",
       "3                                      True   \n",
       "4                                      True   \n",
       "\n",
       "   trafficSource_adwordsClickInfo.page trafficSource_adwordsClickInfo.slot  \\\n",
       "0                                    0                                 NaN   \n",
       "1                                    0                                 NaN   \n",
       "2                                    0                                 NaN   \n",
       "3                                    0                                 NaN   \n",
       "4                                    0                                 NaN   \n",
       "\n",
       "  trafficSource_campaign  trafficSource_isTrueDirect trafficSource_keyword  \\\n",
       "0                    NaN                       False          water bottle   \n",
       "1                    NaN                        True                   NaN   \n",
       "2                    NaN                       False                   NaN   \n",
       "3                    NaN                        True                   NaN   \n",
       "4                    NaN                        True                   NaN   \n",
       "\n",
       "  trafficSource_medium                         trafficSource_referralPath  \\\n",
       "0              organic                                                NaN   \n",
       "1              organic                                          (not set)   \n",
       "2             referral  /a/google.com/transportation/mtv-services/bike...   \n",
       "3               (none)                                          (not set)   \n",
       "4               (none)                                                NaN   \n",
       "\n",
       "  trafficSource_source     visitId  visitNumber  visitStartTime  \\\n",
       "0               google  1508198450            1      1508198450   \n",
       "1               google  1526099341            2      1526099341   \n",
       "2     sites.google.com  1508176307            6      1508176307   \n",
       "3             (direct)  1526064483          166      1526064483   \n",
       "4             (direct)  1508201613            1      1508201613   \n",
       "\n",
       "   customDimensions_index customDimensions_value  \n",
       "0                       4                   EMEA  \n",
       "1                       4                   EMEA  \n",
       "2                       4          North America  \n",
       "3                       4          North America  \n",
       "4                       4          North America  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-08-01 00:00:00\n",
      "2018-10-15 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# convert dates\n",
    "df['date'] = pd.to_datetime(df['date'], infer_datetime_format = True)\n",
    "print(df.date.min())\n",
    "print(df.date.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "FOLD 1/6\n",
      "------------------------------------------------\n",
      "- features: 2017-12-29 - 2018-06-14 (n = 473345)\n",
      "- targets:  2018-07-31 - 2018-09-30 (n = 137013)\n",
      "------------------------------------------------\n",
      "\n",
      "------------------------------------------------\n",
      "FOLD 2/6\n",
      "------------------------------------------------\n",
      "- features: 2017-10-29 - 2018-04-14 (n = 498831)\n",
      "- targets:  2018-05-31 - 2018-07-31 (n = 146339)\n",
      "------------------------------------------------\n",
      "\n",
      "------------------------------------------------\n",
      "FOLD 3/6\n",
      "------------------------------------------------\n",
      "- features: 2017-08-29 - 2018-02-12 (n = 505741)\n",
      "- targets:  2018-03-31 - 2018-05-31 (n = 171157)\n",
      "------------------------------------------------\n",
      "\n",
      "------------------------------------------------\n",
      "FOLD 4/6\n",
      "------------------------------------------------\n",
      "- features: 2017-06-29 - 2017-12-13 (n = 494837)\n",
      "- targets:  2018-01-29 - 2018-03-31 (n = 186193)\n",
      "------------------------------------------------\n",
      "\n",
      "------------------------------------------------\n",
      "FOLD 5/6\n",
      "------------------------------------------------\n",
      "- features: 2017-05-01 - 2017-10-15 (n = 425146)\n",
      "- targets:  2017-12-01 - 2018-01-31 (n = 180494)\n",
      "------------------------------------------------\n",
      "\n",
      "------------------------------------------------\n",
      "FOLD 6/6\n",
      "------------------------------------------------\n",
      "- features: 2017-03-01 - 2017-08-15 (n = 377857)\n",
      "- targets:  2017-10-01 - 2017-12-01 (n = 197893)\n",
      "------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set windows\n",
    "train_per = 168\n",
    "valid_per = 62\n",
    "valid_gap = 46\n",
    "\n",
    "# number of folds\n",
    "num_folds = 6\n",
    "\n",
    "# placeholders\n",
    "x_idx = []\n",
    "y_idx = []\n",
    "\n",
    "# partitioning loop\n",
    "for i in range(num_folds):\n",
    "\n",
    "    # validation dates\n",
    "    if i == 0:\n",
    "        v_end = df['date'].max() - pd.DateOffset(days = 15)\n",
    "    else:\n",
    "        v_end = df['date'].max() - pd.DateOffset(days = 15) - pd.DateOffset(months = i*2) + pd.DateOffset(days = 1)\n",
    "    v_start = v_end - pd.DateOffset(days = valid_per - 1)\n",
    "\n",
    "    # training dates\n",
    "    t_end   = v_start - pd.DateOffset(days = valid_gap + 1)\n",
    "    t_start = t_end - pd.DateOffset(days = train_per - 1)\n",
    "    \n",
    "    # extract index\n",
    "    x_idx.append(list(df[(df.date >= t_start) & (df.date <= t_end)].index))\n",
    "    y_idx.append(list(df[(df.date >= v_start) & (df.date <= v_end)].index))\n",
    "    \n",
    "    # print information\n",
    "    print('------------------------------------------------')\n",
    "    print(\"FOLD \" + str(i + 1) + '/' + str(num_folds))\n",
    "    print('------------------------------------------------')\n",
    "    print('- features: ' + str(t_start)[0:10] + ' - ' + str(t_end)[0:10] + ' (n = ' + str(len(x_idx[i])) + ')')\n",
    "    print('- targets:  ' + str(v_start)[0:10] + ' - ' + str(v_end)[0:10] + ' (n = ' + str(len(y_idx[i])) + ')')\n",
    "    print('------------------------------------------------')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAIN FUNCTION TO FEATURIZE THE DATA\n",
    "def create_data(df, x_idx, y_idx, old_months = 6, agg_months = 1):\n",
    "\n",
    "    ###### DATA PARTITIONING\n",
    "\n",
    "    # extract X \n",
    "    x = df.iloc[x_idx]\n",
    "    ids = x.fullVisitorId.unique()\n",
    "    \n",
    "    # append previous months to train\n",
    "    old_x = x.date.min() - pd.DateOffset(months = old_months)\n",
    "    old_x = df[(df.date >= old_x) & (df.date < x.date.min()) & (df.fullVisitorId.isin(ids))]\n",
    "    x = pd.concat([x, old_x], axis = 0)\n",
    "    \n",
    "    # extract Y\n",
    "    if len(y_idx) > 0:\n",
    "        \n",
    "        y = df.iloc[y_idx][['fullVisitorId', 'totals_transactionRevenue']]\n",
    "        y['target'] = np.log1p(y.groupby('fullVisitorId').totals_transactionRevenue.transform('sum'))\n",
    "        y = y[['fullVisitorId', 'target']]\n",
    "        y.drop_duplicates(inplace = True)\n",
    "        y = y.loc[y.fullVisitorId.isin(ids)]\n",
    "\n",
    "        \n",
    "    \n",
    "    ###### FEATURE ENGINEERING\n",
    "    \n",
    "    ### AGGREGATIONS\n",
    "\n",
    "    # aggregations (total)\n",
    "    grp_x = aggregate_data(x, group_var = 'fullVisitorId')\n",
    "    \n",
    "    '''\n",
    "    # aggregations (monthly)\n",
    "    x = add_months_to_end(x, months = agg_months)\n",
    "    for t in range(agg_months):\n",
    "        tmp_x = x.loc[x.months_to_end <= (t + 1)]\n",
    "        tmp_grp_x = aggregate_data(tmp_x, group_var = 'fullVisitorId', label = 'm' + str(t+1))\n",
    "        grp_x     =  grp_x.merge(tmp_grp_x, how = 'left', on = 'fullVisitorId')      \n",
    "    '''\n",
    "\n",
    "    \n",
    "    ### OTHER VARIABLES\n",
    "    \n",
    "    # number of visits\n",
    "    drops = list(grp_x.filter(like = 'visitNumber').columns)\n",
    "    for var in drops:\n",
    "        del grp_x[var]\n",
    "    x['num_visits'] = x.groupby('fullVisitorId').visitNumber.transform('max')\n",
    "    tmp = x[['fullVisitorId', 'num_visits']].drop_duplicates()\n",
    "    grp_x = grp_x.merge(tmp, how = 'left', on = 'fullVisitorId')\n",
    "    \n",
    "    # number of paying visits\n",
    "    x_tmp = x[x.totals_transactionRevenue > 0]\n",
    "    x_tmp['num_paying_visits'] = x_tmp.groupby('fullVisitorId').visitId.transform('count')\n",
    "    x_tmp = x_tmp[['fullVisitorId', 'num_paying_visits']].drop_duplicates()\n",
    "    grp_x = grp_x.merge(x_tmp, how = 'left', on = 'fullVisitorId')\n",
    "    \n",
    "    # add recency\n",
    "    x['recency'] = x.groupby('fullVisitorId').date.transform('max')\n",
    "    x['recency'] = ((x.date.max() - x['recency']) / np.timedelta64(1, 'D')).astype(int)\n",
    "    tmp = x[['fullVisitorId', 'recency']].drop_duplicates()\n",
    "    grp_x = grp_x.merge(tmp, how = 'left', on = 'fullVisitorId')\n",
    "\n",
    "    # add frequency\n",
    "    x['frequency'] = x.groupby('fullVisitorId').date.transform('count')\n",
    "    tmp = x[['fullVisitorId', 'frequency']].drop_duplicates()\n",
    "    grp_x = grp_x.merge(tmp, how = 'left', on = 'fullVisitorId')\n",
    "    grp_x['frequency'].fillna(0, inplace = True)\n",
    "    \n",
    "    # day of the week\n",
    "    #tmp = encode_date(x)\n",
    "    #tmp = tmp[['fullVisitorId', 'date_Dayofweek']]\n",
    "    #tmp = tmp.groupby('fullVisitorId').agg([(\"mode\", lambda x: scipy.stats.mode(x)[0][0])])\n",
    "    #tmp.columns = [\"_\".join(col).strip() for col in tmp.columns.values]\n",
    "    #tmp = tmp.sort_index()\n",
    "    #grp_x = grp_x.merge(tmp, how = 'left', on = 'fullVisitorId')\n",
    "    \n",
    "    \n",
    "    ###### ALIGNMENT\n",
    "    \n",
    "    if len(y_idx) > 0:\n",
    "    \n",
    "        # merge zeros for new ids\n",
    "        new_ids = list(set(grp_x.fullVisitorId) - set(y.fullVisitorId))\n",
    "        new_ids = grp_x[grp_x.fullVisitorId.isin(new_ids)][['fullVisitorId']]\n",
    "        y = y.merge(new_ids, how = 'outer', on = 'fullVisitorId')\n",
    "        y.fillna(0, inplace = True)\n",
    "\n",
    "        # align X and Y\n",
    "        y = y.sort_values('fullVisitorId')['target'].reset_index(drop = True)\n",
    "        x = grp_x.sort_values('fullVisitorId').reset_index(drop = True)\n",
    "        return x, y\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        x = grp_x.sort_values('fullVisitorId').reset_index(drop = True)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "- features: 2018-05-01 - 2018-10-15 (n = 401589)\n",
      "- targets:  2018-12-01 - 2019-01-31 (n = 0)\n",
      "------------------------------------------------\n",
      "- Preparing the dataset...\n",
      "- Extracted 3 factors and 36 numerics...\n",
      "- Aggregating numeric features...\n",
      "- Aggregating factor features...\n",
      "- Final dimensions: (296530, 38)\n"
     ]
    }
   ],
   "source": [
    "##### CONSTRUCT TEST DATA FIRST\n",
    "\n",
    "# validation dates\n",
    "v_end = pd.Timestamp('2019-01-31 00:00:00')\n",
    "v_start = v_end - pd.DateOffset(days = valid_per - 1)\n",
    "\n",
    "# training dates\n",
    "t_end   = v_start - pd.DateOffset(days = valid_gap + 1)\n",
    "t_start = t_end - pd.DateOffset(days = train_per - 1)\n",
    "\n",
    "# extract index\n",
    "xt_idx = list(df[(df.date >= t_start) & (df.date <= t_end)].index)\n",
    "yt_idx = list(df[(df.date >= v_start) & (df.date <= v_end)].index)\n",
    "\n",
    "# print information\n",
    "print('------------------------------------------------')\n",
    "print('- features: ' + str(t_start)[0:10] + ' - ' + str(t_end)[0:10] + ' (n = ' + str(len(xt_idx)) + ')')\n",
    "print('- targets:  ' + str(v_start)[0:10] + ' - ' + str(v_end)[0:10] + ' (n = ' + str(len(yt_idx)) + ')')\n",
    "print('------------------------------------------------')\n",
    "\n",
    "# construct data\n",
    "test_x = create_data(df, xt_idx, yt_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop bad features\n",
    "excluded_feats = ['fullVisitorId', 'visitId', 'visitStartTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ynozDG6yivwQ"
   },
   "outputs": [],
   "source": [
    "### PARAMETERS\n",
    "\n",
    "# LGB parameters\n",
    "lgb_params = {\n",
    "    'boosting_type':   'gbdt',\n",
    "    'objective':       'rmse',\n",
    "    'metric':          'rmse',\n",
    "    'subsample':        0.9,\n",
    "    'feature_fraction': 0.7,\n",
    "    'lambda_l1':        0.03,\n",
    "    'lambda_l2':        0.03,\n",
    "    'min_split_gain':   0.01,\n",
    "    'min_child_weight': 5,\n",
    "    'silent':           True,\n",
    "    'verbosity':        -1,\n",
    "    'learning_rate':    0.03,\n",
    "    'max_depth':        3,\n",
    "    'n_estimators':     1000,\n",
    "    'nthread' :         16\n",
    "}\n",
    "\n",
    "# loss function\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "- Preparing the dataset...\n",
      "- Extracted 3 factors and 36 numerics...\n",
      "- Aggregating numeric features...\n",
      "- Aggregating factor features...\n",
      "- Final dimensions: (366163, 38)\n",
      "- Preparing the dataset...\n",
      "- Extracted 3 factors and 36 numerics...\n",
      "- Aggregating numeric features...\n",
      "- Aggregating factor features...\n",
      "- Final dimensions: (385330, 38)\n",
      "------------------------------------------\n",
      "Training until validation scores don't improve for 50 rounds.\n"
     ]
    }
   ],
   "source": [
    "### CROSS-VALIDATION LOOP\n",
    "\n",
    "# placeholders\n",
    "clfs = []\n",
    "oof_preds = []\n",
    "oof_reals = []\n",
    "test_preds = None\n",
    "importances = pd.DataFrame()\n",
    "\n",
    "# modeling loop\n",
    "start  = time.time()\n",
    "for i in range(5):\n",
    "    \n",
    "    # data partitioning\n",
    "    print('------------------------------------------')\n",
    "    val_x, val_y = create_data(df, x_idx[i],   y_idx[i])\n",
    "    trn_x, trn_y = create_data(df, x_idx[i+1], y_idx[i+1])\n",
    "    \n",
    "    # drop bad features\n",
    "    bad_feats = [list(trn_x.filter(like = f).columns) for f in excluded_feats]\n",
    "    bad_feats = [item for sublist in bad_feats for item in sublist]\n",
    "    features = [f for f in trn_x.columns if f not in bad_feats]\n",
    "    trn_x = trn_x[features]\n",
    "    val_x = val_x[features]\n",
    "    tst_x = test_x[features]\n",
    "\n",
    "    # label encoding   \n",
    "    trn_x['trainid'] = 1\n",
    "    val_x['trainid'] = 0\n",
    "    tst_x['trainid'] = -1\n",
    "    x = encode_factors(pd.concat([trn_x, val_x, tst_x], axis = 0), method = 'label')\n",
    "    trn_x = x[x.trainid == 1]\n",
    "    val_x = x[x.trainid == 0]\n",
    "    tst_x = x[x.trainid == -1]\n",
    "    del x, trn_x['trainid'], val_x['trainid'], tst_x['trainid']\n",
    "\n",
    "    # train the model\n",
    "    print('------------------------------------------')\n",
    "    clf = lgb.LGBMRegressor(**lgb_params) \n",
    "    clf.fit(\n",
    "        trn_x, trn_y,\n",
    "        eval_set              = [(trn_x, trn_y), (val_x, val_y)],\n",
    "        eval_metric           = 'rmse',\n",
    "        verbose               = 50,\n",
    "        early_stopping_rounds = 50,\n",
    "    )\n",
    "    clfs.append(clf)\n",
    "\n",
    "    # OOF predictions\n",
    "    oof_preds.append(list(clf.predict(val_x, num_iteration = clf.best_iteration_)))\n",
    "    oof_reals.append(val_y)\n",
    "    \n",
    "    # TEST predictions\n",
    "    cur_test_preds = clf.predict(tst_x[features], num_iteration = clf.best_iteration_)\n",
    "    cur_test_preds = pd.Series(cur_test_preds)\n",
    "    cur_test_preds[cur_test_preds < 0] = 0\n",
    "    cur_test_preds = cur_test_preds.values\n",
    "    if test_preds is None:\n",
    "        test_preds =  cur_test_preds / 5\n",
    "    else:\n",
    "        test_preds += cur_test_preds / 5\n",
    "    \n",
    "    # feedback\n",
    "    print('------------------------------------------')\n",
    "    print('Fold ' + str(i + 1) + ': RMSE = ' + str(round(rmse(val_y, clf.predict(val_x, num_iteration = clf.best_iteration_)), 6)))  \n",
    "    print('------------------------------------------')\n",
    "    print('')\n",
    "\n",
    "    # variable importance\n",
    "    imp_df = pd.DataFrame()\n",
    "    imp_df['feature'] = features\n",
    "    imp_df['gain'] = clf.feature_importances_\n",
    "    imp_df['fold'] = i + 1\n",
    "    importances = pd.concat([importances, imp_df], axis = 0, sort = False)\n",
    "    \n",
    "    # clean up\n",
    "    gc.collect()\n",
    "    \n",
    "# OOF predictions\n",
    "oof_preds = [item for sublist in oof_preds for item in sublist]\n",
    "oof_reals = [item for sublist in oof_reals for item in sublist]\n",
    "oof_preds_df = pd.DataFrame({'pred': oof_preds, 'real': oof_reals})\n",
    "    \n",
    "# print performance\n",
    "cv_perf = rmse(oof_reals, oof_preds)\n",
    "print('')\n",
    "print('OOF RMSE: %.6f ' % cv_perf)\n",
    "print('Done in %6.1f minutes' % ((time.time() - start) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### TRACKING RESULTS\n",
    "\n",
    "# numeric sums:           0.283247\n",
    "# numeric means & sums:   0.283089\n",
    "# correct visit number:   0.283058\n",
    "# add modes for 3 facs:   0.283031\n",
    "# add # paying visits:    0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibration of porbs\n",
    "preds = pd.Series(oof_preds)\n",
    "preds[preds < 0] = 0\n",
    "print('RMSE before: %.6f ' % rmse(oof_reals, oof_preds))\n",
    "print('RMSE after:  %.6f ' % rmse(oof_reals, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### VARIABLE IMPORTANCE\n",
    "\n",
    "# load importance \n",
    "top_feats = 50\n",
    "cols = importances[[\"gain\", \"feature\"]].groupby(\"feature\").mean().sort_values(by = \"gain\", ascending = False)[0:top_feats].index\n",
    "importance = importances.loc[importances.feature.isin(cols)]\n",
    "importance = importance.sort_values(by = \"gain\", ascending = False)\n",
    "\n",
    "# plot variable importance\n",
    "plt.figure(figsize = (10, 10))\n",
    "sns.barplot(x = \"gain\", y = \"feature\", data = importance)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../var_importance.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission\n",
    "sub = pd.DataFrame(test_preds, columns = ['predictedLogRevenue'])\n",
    "sub['fullVisitorId'] = test_x['fullVisitorId'].values\n",
    "sub = sub[['fullVisitorId', 'predictedLogRevenue']]\n",
    "print('Predictions shape: ', sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file name\n",
    "model = 'lgb_v1'\n",
    "perf  = str(round(cv_perf, 6))[2:8]\n",
    "name  = model + '_' + perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export submission\n",
    "sub.to_csv('../submissions/' + str(name) + '.csv', index = False)\n",
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export OOF preds\n",
    "oof_preds_df.to_csv('../oof_preds/' + str(name) + '.csv', index = False)\n",
    "oof_preds_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
