{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "from ast import literal_eval\n",
    "\n",
    "import os\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas options\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# garbage collection\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FUNCTION 1: LOADING DATA WITH JSON\n",
    "def read_csv_with_json_zipped(path, json_cols, nrows = None):\n",
    "        \n",
    "    # import data frame\n",
    "    df = pd.read_csv(path, \n",
    "                     converters = {column: json.loads for column in json_cols}, \n",
    "                     compression = 'zip',\n",
    "                     dtype = {'fullVisitorId': 'str'},\n",
    "                     nrows = nrows)\n",
    "    \n",
    "    # extract values\n",
    "    for column in json_cols:\n",
    "        column_as_df = json_normalize(df[column])\n",
    "        column_as_df.columns = [f\"{column}_{subcolumn}\" for subcolumn in column_as_df.columns]\n",
    "        df = df.drop(column, axis = 1).merge(column_as_df, right_index = True, left_index = True)\n",
    "\n",
    "    # return data\n",
    "    print(f\"Loaded {os.path.basename(path)}: {df.shape}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FUNCTION 1: LOADING DATA WITH JSON\n",
    "def read_csv_with_json(path, json_cols, nrows = None):\n",
    "        \n",
    "    # import data frame\n",
    "    df = pd.read_csv(path, \n",
    "                     converters = {column: json.loads for column in json_cols}, \n",
    "                     dtype = {'fullVisitorId': 'str'},\n",
    "                     nrows = nrows)\n",
    "    \n",
    "    # extract values\n",
    "    for column in json_cols:\n",
    "        column_as_df = json_normalize(df[column])\n",
    "        column_as_df.columns = [f\"{column}_{subcolumn}\" for subcolumn in column_as_df.columns]\n",
    "        df = df.drop(column, axis = 1).merge(column_as_df, right_index = True, left_index = True)\n",
    "\n",
    "    # return data\n",
    "    print(f\"Loaded {os.path.basename(path)}: {df.shape}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FUNCTION 2: UNFOLD CUSTOM DIMENSIONS\n",
    "def add_custom_dim(df):\n",
    "\n",
    "    # extract custom dimensions\n",
    "    df['customDimensions'] = df['customDimensions'].apply(literal_eval)\n",
    "    df['customDimensions'] = df['customDimensions'].str[0]\n",
    "    df['customDimensions'] = df['customDimensions'].apply(lambda x: {'index':np.NaN,'value':np.NaN} if pd.isnull(x) else x)\n",
    "\n",
    "    column_as_df = json_normalize(df['customDimensions'])\n",
    "    column_as_df.columns = [f\"customDimensions_{subcolumn}\" for subcolumn in column_as_df.columns]\n",
    "    df = df.drop('customDimensions', axis=1).merge(column_as_df, right_index = True, left_index = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FUNCTION 3: FILL NA\n",
    "def fill_na(df):\n",
    "    \n",
    "    \n",
    "    ##### IMPUTE NA DIFFERENTLY\n",
    "    \n",
    "    # NA = unknown\n",
    "    to_NA_cols = ['trafficSource_adContent',\n",
    "                  'trafficSource_adwordsClickInfo.adNetworkType',\n",
    "                  'trafficSource_adwordsClickInfo.slot',\n",
    "                  'trafficSource_adwordsClickInfo.gclId',\n",
    "                  'trafficSource_keyword',\n",
    "                  'trafficSource_referralPath',\n",
    "                  'customDimensions_value']\n",
    "\n",
    "    # NA = zero\n",
    "    to_0_cols = ['totals_transactionRevenue',\n",
    "                 'trafficSource_adwordsClickInfo.page',\n",
    "                 'totals_sessionQualityDim','totals_bounces',\n",
    "                 'totals_timeOnSite',\n",
    "                 'totals_newVisits',\n",
    "                 'totals_pageviews',\n",
    "                 'customDimensions_index',\n",
    "                 'totals_transactions',\n",
    "                 'totals_totalTransactionRevenue']\n",
    "\n",
    "    # NA = TRUE / FALSE\n",
    "    to_true_cols  = ['trafficSource_adwordsClickInfo.isVideoAd']\n",
    "    to_false_cols = ['trafficSource_isTrueDirect']\n",
    "    \n",
    "    # impute missings\n",
    "    df[to_NA_cols]    = df[to_NA_cols].fillna('NA')\n",
    "    df[to_0_cols]     = df[to_0_cols].fillna(0)\n",
    "    df[to_true_cols]  = df[to_true_cols].fillna(True)\n",
    "    df[to_false_cols] = df[to_false_cols].fillna(False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##### REPLACE SOME LEVELS WITH NA\n",
    "    \n",
    "    # not available, not provided, etc.\n",
    "    cols_to_replace = {\n",
    "        'socialEngagementType' : 'Not Socially Engaged',\n",
    "        'device_browserSize' : 'not available in demo dataset', \n",
    "        'device_flashVersion' : 'not available in demo dataset', \n",
    "        'device_browserVersion' : 'not available in demo dataset', \n",
    "        'device_language' : 'not available in demo dataset',\n",
    "        'device_mobileDeviceBranding' : 'not available in demo dataset',\n",
    "        'device_mobileDeviceInfo' : 'not available in demo dataset',\n",
    "        'device_mobileDeviceMarketingName' : 'not available in demo dataset',\n",
    "        'device_mobileDeviceModel' : 'not available in demo dataset',\n",
    "        'device_mobileInputSelector' : 'not available in demo dataset',\n",
    "        'device_operatingSystemVersion' : 'not available in demo dataset',\n",
    "        'device_screenColors' : 'not available in demo dataset',\n",
    "        'device_screenResolution' : 'not available in demo dataset',\n",
    "        'geoNetwork_city' : 'not available in demo dataset',\n",
    "        'geoNetwork_cityId' : 'not available in demo dataset',\n",
    "        'geoNetwork_latitude' : 'not available in demo dataset',\n",
    "        'geoNetwork_longitude' : 'not available in demo dataset',\n",
    "        'geoNetwork_metro' : ['not available in demo dataset', '(not set)'], \n",
    "        'geoNetwork_networkDomain' : ['unknown.unknown', '(not set)'], \n",
    "        'geoNetwork_networkLocation' : 'not available in demo dataset',\n",
    "        'geoNetwork_region' : 'not available in demo dataset',\n",
    "        'trafficSource_adwordsClickInfo.criteriaParameters' : 'not available in demo dataset',\n",
    "        'trafficSource_campaign' : '(not set)', \n",
    "        'trafficSource_keyword' : ['(not provided)', '(not set)'], \n",
    "        'networkDomain': '(not set)', \n",
    "        'city': '(not set)'\n",
    "    }\n",
    "    df = df.replace(cols_to_replace,'NA')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON columns\n",
    "json_cols = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "\n",
    "# import data\n",
    "if getpass.getuser() == 'zinovyee.hub':\n",
    "    train = read_csv_with_json_zipped(\"../../train_v2.csv.zip\",  json_cols = json_cols)\n",
    "    test = read_csv_with_json_zipped(\"../../test_v2.csv.zip\",   json_cols = json_cols)\n",
    "else:\n",
    "    train = read_csv_with_json(\"../data/train_v2.csv\", json_cols = json_cols, nrows = 100)\n",
    "    test = read_csv_with_json(\"../data/test_v2.csv\",   json_cols = json_cols, nrows = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop hits [TEMPORARY]\n",
    "if getpass.getuser() == 'zinovyee.hub':\n",
    "    train.drop('hits', axis=1, inplace=True)\n",
    "    test.drop('hits', axis=1, inplace=True)\n",
    "else:\n",
    "        del train['hits']\n",
    "        del test['hits']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. MERGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align columns\n",
    "train = train.reindex_axis(sorted(train.columns), axis = 1)\n",
    "test  = test.reindex_axis(sorted(test.columns),   axis = 1)\n",
    "\n",
    "# delete vars not in test\n",
    "del train['trafficSource_campaignCode']\n",
    "\n",
    "# check equalty\n",
    "train.columns == test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate\n",
    "df = pd.concat([train, test], axis = 0)\n",
    "del train, test\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfold custom dimensions\n",
    "print(df.shape)\n",
    "df = add_custom_dim(df)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missings\n",
    "df = fill_na(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to integers\n",
    "to_int = ['customDimensions_index',\n",
    "          'totals_bounces',\n",
    "          'totals_newVisits',\n",
    "          'totals_pageviews',\n",
    "          'totals_hits',\n",
    "          'totals_sessionQualityDim',\n",
    "          'totals_visits',\n",
    "          'totals_timeOnSite',\n",
    "          'trafficSource_adwordsClickInfo.page',\n",
    "          'totals_transactions',\n",
    "          'totals_transactionRevenue',\n",
    "          'totals_totalTransactionRevenue']\n",
    "for col in to_int :\n",
    "    df[col] = df[col].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date\n",
    "df['date'] = pd.to_datetime(df['date'].astype('str'), infer_datetime_format = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns with a single value\n",
    "print(df.shape)\n",
    "df = df.loc[:, df.nunique(dropna = False) != 1]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert boolean to objects\n",
    "bools = ['device_isMobile', 'trafficSource_adwordsClickInfo.isVideoAd', 'trafficSource_isTrueDirect']\n",
    "for var in bools:\n",
    "    df[var] = df[var].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. EXPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export CSV\n",
    "df.to_csv(\"../data/data_v1.csv.gz\", index = False, compression = \"gzip\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
